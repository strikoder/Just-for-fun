{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObWritikFHGnYCCzu3hHuP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3635s"],"metadata":{"id":"sMd7OgYPZQUO"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N65xv4DCZFkK","executionInfo":{"status":"ok","timestamp":1683797843308,"user_tz":-180,"elapsed":1273,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"a7131cd8-ff4b-48b2-ed0d-1ed31e4569bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-11 09:37:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt’\n","\n","\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.008s  \n","\n","2023-05-11 09:37:21 (134 MB/s) - ‘input.txt’ saved [1115394/1115394]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","source":["# read it in to inspect it\n","with open('input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()"],"metadata":{"id":"GS59NTZddYH1","executionInfo":{"status":"ok","timestamp":1683797843575,"user_tz":-180,"elapsed":9,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(\"length of dataset in characters: \", len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMmIews2dfFZ","executionInfo":{"status":"ok","timestamp":1683797843575,"user_tz":-180,"elapsed":8,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"444ce432-e232-42b1-aff3-2ea7ff125d74"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset in characters:  1115394\n"]}]},{"cell_type":"code","source":["# let's look at the first 1000 characters\n","print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzQN3f5Idj5j","executionInfo":{"status":"ok","timestamp":1683797843575,"user_tz":-180,"elapsed":8,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"36a1f492-60b8-4f2c-c203-c26718ddcdfe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"code","source":["# here are all the unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMwWguBddlzp","executionInfo":{"status":"ok","timestamp":1683797843575,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"f7d01b93-304f-413b-f050-b14917f5b0ff"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}]},{"cell_type":"markdown","source":["Encoding - decoding, Try to implement the OPENAI decoding-encoding methods later"],"metadata":{"id":"Ndb1F9pDoN3j"}},{"cell_type":"code","source":["# create a mapping from characters to integers\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n","decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n","\n","print(encode(\"hii there\"))\n","print(decode(encode(\"hii there\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NxEkh-ljoL_X","executionInfo":{"status":"ok","timestamp":1683797843576,"user_tz":-180,"elapsed":5,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"fdfbdca3-3c52-477a-d149-3dc69b2ccfbc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[46, 47, 47, 1, 58, 46, 43, 56, 43]\n","hii there\n"]}]},{"cell_type":"code","source":["import torch \n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(data.shape, data.dtype)\n","print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMqQL4UToW-7","executionInfo":{"status":"ok","timestamp":1683797848605,"user_tz":-180,"elapsed":5032,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"e4f34e53-c9a7-4f6f-a0b0-9766b4b502f7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1115394]) torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"code","source":["n = int(0.7*len(data)) # first 90% will be train, rest val\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"id":"zl0MYehjocOJ","executionInfo":{"status":"ok","timestamp":1683797848605,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["block_size = 8\n","train_data[:block_size+1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3g9fOy5ZoifJ","executionInfo":{"status":"ok","timestamp":1683797848606,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"dce29606-1ba8-4c44-8c94-abd85546ff55"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f\"when input is {context} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BHTNTD7ol29","executionInfo":{"status":"ok","timestamp":1683797848606,"user_tz":-180,"elapsed":10,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"5a060835-fd91-4c20-cb38-5895063eeb1c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["when input is tensor([18]) the target: 47\n","when input is tensor([18, 47]) the target: 56\n","when input is tensor([18, 47, 56]) the target: 57\n","when input is tensor([18, 47, 56, 57]) the target: 58\n","when input is tensor([18, 47, 56, 57, 58]) the target: 1\n","when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n","when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4 # how many independent sequences will we process in parallel?\n","block_size = 8 # what is the maximum context length for predictions?\n","\n","def get_batch(split):\n","    # generate a small batch of data of inputs x and targets y\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    return x, y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('----')\n","\n","for b in range(batch_size): # batch dimension\n","    for t in range(block_size): # time dimension\n","        context = xb[b, :t+1]\n","        target = yb[b,t]\n","        print(f\"when input is {context.tolist()} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ynKblL3otPb","executionInfo":{"status":"ok","timestamp":1683797848606,"user_tz":-180,"elapsed":9,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"e8da3772-7f04-44b8-f11d-e7d8fdd43397"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[47, 41, 43, 57, 58, 43, 56,  6],\n","        [ 1, 40, 56, 53, 58, 46, 43, 56],\n","        [59, 43, 57, 58,  6,  1, 39, 50],\n","        [43,  1, 51, 47, 50, 42, 10,  0]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[41, 43, 57, 58, 43, 56,  6,  1],\n","        [40, 56, 53, 58, 46, 43, 56,  1],\n","        [43, 57, 58,  6,  1, 39, 50, 58],\n","        [ 1, 51, 47, 50, 42, 10,  0, 13]])\n","----\n","when input is [47] the target: 41\n","when input is [47, 41] the target: 43\n","when input is [47, 41, 43] the target: 57\n","when input is [47, 41, 43, 57] the target: 58\n","when input is [47, 41, 43, 57, 58] the target: 43\n","when input is [47, 41, 43, 57, 58, 43] the target: 56\n","when input is [47, 41, 43, 57, 58, 43, 56] the target: 6\n","when input is [47, 41, 43, 57, 58, 43, 56, 6] the target: 1\n","when input is [1] the target: 40\n","when input is [1, 40] the target: 56\n","when input is [1, 40, 56] the target: 53\n","when input is [1, 40, 56, 53] the target: 58\n","when input is [1, 40, 56, 53, 58] the target: 46\n","when input is [1, 40, 56, 53, 58, 46] the target: 43\n","when input is [1, 40, 56, 53, 58, 46, 43] the target: 56\n","when input is [1, 40, 56, 53, 58, 46, 43, 56] the target: 1\n","when input is [59] the target: 43\n","when input is [59, 43] the target: 57\n","when input is [59, 43, 57] the target: 58\n","when input is [59, 43, 57, 58] the target: 6\n","when input is [59, 43, 57, 58, 6] the target: 1\n","when input is [59, 43, 57, 58, 6, 1] the target: 39\n","when input is [59, 43, 57, 58, 6, 1, 39] the target: 50\n","when input is [59, 43, 57, 58, 6, 1, 39, 50] the target: 58\n","when input is [43] the target: 1\n","when input is [43, 1] the target: 51\n","when input is [43, 1, 51] the target: 47\n","when input is [43, 1, 51, 47] the target: 50\n","when input is [43, 1, 51, 47, 50] the target: 42\n","when input is [43, 1, 51, 47, 50, 42] the target: 10\n","when input is [43, 1, 51, 47, 50, 42, 10] the target: 0\n","when input is [43, 1, 51, 47, 50, 42, 10, 0] the target: 13\n"]}]},{"cell_type":"code","source":["print(xb) # our input to the transformer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMhAxDB-o9Ss","executionInfo":{"status":"ok","timestamp":1683797848606,"user_tz":-180,"elapsed":8,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"af618a7e-4ad7-4464-fb96-0ed9df2ff5b9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[47, 41, 43, 57, 58, 43, 56,  6],\n","        [ 1, 40, 56, 53, 58, 46, 43, 56],\n","        [59, 43, 57, 58,  6,  1, 39, 50],\n","        [43,  1, 51, 47, 50, 42, 10,  0]])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","torch.manual_seed(42)\n","\n","class BigramLanguageModel(nn.Module):\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        self.token_embedding_table=nn.Embedding(vocab_size, vocab_size)\n","\n","    def forward(self,idx,targets=None):\n","        #idx and targets are both of (B,T) dimensions tensor of int\n","        logits = self.token_embedding_table(idx) # (B,T,C)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits=logits.view(B*T, C) # converting it to 2 dim\n","            targets= targets.view(B*T) # 1 dim\n","            loss = F.cross_entropy(logits, targets)\n","        return logits, loss\n","    \n","    def generate(self, idx, max_new_tokens):\n","        #idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # get pred through forward method\n","            logits, loss=self(idx)\n","            # focus only on the last time step\n","            logits = logits [:,-1,:] # (B,C)\n","            probs=F.softmax(logits, dim=-1)\n","            # sample from the distribution\n","            idx_next=torch.multinomial(probs,num_samples=1) # (B, 1)\n","            # append the sampled index to the running sequence\n","            idx = torch.cat((idx,idx_next),dim=1) # (B, T+1)\n","        return idx"],"metadata":{"id":"RhB2ItuZpTA9","executionInfo":{"status":"ok","timestamp":1683797848606,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model = BigramLanguageModel(vocab_size)\n","logits, loss = model(xb, yb)\n","print(logits.shape)\n","print(loss)\n","print(\"\\nThe generated text:\")\n","print(decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JzdUbQvtPEj","executionInfo":{"status":"ok","timestamp":1683797848607,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"046610c4-98ce-4dd9-d050-962f01d6b7b7"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 65])\n","tensor(4.7143, grad_fn=<NllLossBackward0>)\n","\n","The generated text:\n","\n","uoiaF$z\n","M?kI;h\n","DbuMG,H3LYNmrDxKgTpvAKOF-jU.hc;fBMTGa-IS\n","g3lEb&ZQ,l;:m;lpcNN\n","KpVEYRIIM,'hCRbMAcWTkrnH\n"]}]},{"cell_type":"code","source":["# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"],"metadata":{"id":"XE0nhI4bpYs8","executionInfo":{"status":"ok","timestamp":1683797848607,"user_tz":-180,"elapsed":5,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(1000): # increase number of steps for good results... \n","    \n","    # sample a batch of data\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","print(loss.item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MfQ1hHz0pZlk","executionInfo":{"status":"ok","timestamp":1683797849991,"user_tz":-180,"elapsed":1389,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"fb0688e4-4014-4fc0-fbf5-ca0474b5e7ee"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["3.6575355529785156\n"]}]},{"cell_type":"code","source":["print(decode(model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOfQ_q6Vtp0a","executionInfo":{"status":"ok","timestamp":1683797849991,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"26024373-6ffd-4e0c-b5b0-809dbd3ba41b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","whFel3Ywatm3lDI;KKbIAMvo?TQBCaghcYpHEMugn;'Jo fkr,kERAMEbrg.VzwfUN?HISho ; s&I!DxyasMyGERzs?ERxxaltFKrW,jhmKp faSt;BWf wZ&hSkFW'XMeTWn hks\n","z  tCYhXERqfO:cDTiH-ItjvkmK$LyTPHaTorUCiCOrPqYFEREOMTJqU'Z:maF&MfU.VC;fnqu' u wu3&JIWcFa-KbTeuemavFfFCLoAD cz&dKuse lVERDeGjhLispcO tYp'IIAl!,LMgcA.GmirFk\n","EbMPOriInmb wERyl:.JE:PxDWb&Pwjv?;\n","\n","3n\n","DpoARLJqo&Wd!wr, e.lzJp,'U u,qBA;$uOlxxxxtDWagu p\n","EbIYiQgl'?-jARgsOxRoOVKpriirJu'Hae3s'VzJ\n","guXQrazQzbSi\n","I;Bg-BiqH$imKL&IMH3FSefYy;hm-.zJP: hk$,DFt\n","DW;HUpDKKqCOPIJPSp&e\n"]}]},{"cell_type":"markdown","source":["The mathematical trick in self-attention"],"metadata":{"id":"q89IgAU5MX0q"}},{"cell_type":"code","source":["# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n","torch.manual_seed(42)\n","a = torch.tril(torch.ones(3, 3))\n","a = a / torch.sum(a, 1, keepdim=True)\n","b = torch.randint(0,10,(3,2)).float()\n","c = a @ b\n","print('a=')\n","print(a)\n","print('--')\n","print('b=')\n","print(b)\n","print('--')\n","print('c=')\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00oKGav-tt5Y","executionInfo":{"status":"ok","timestamp":1683798217726,"user_tz":-180,"elapsed":472,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"83b81dac-dfd4-4332-8df6-ea7a6aa7eded"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["a=\n","tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","--\n","b=\n","tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","--\n","c=\n","tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}]},{"cell_type":"code","source":["# consider the following toy example:\n","\n","torch.manual_seed(42)\n","B,T,C = 4,8,2 # batch, time, channels\n","x = torch.randn(B,T,C)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glA3W8iHMc5D","executionInfo":{"status":"ok","timestamp":1683798227246,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"e53d33b6-3ad0-4fbf-873f-c89d0393ef1c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 2])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["There's 3 ways to get the array a "],"metadata":{"id":"F25RcwxEMkbk"}},{"cell_type":"markdown","source":["* first method"],"metadata":{"id":"_d3KN7JoMrVT"}},{"cell_type":"code","source":["# We want x[b,t] = mean_{i<=t} x[b,i]\n","xbow = torch.zeros((B,T,C))\n","for b in range(B):\n","    for t in range(T):\n","        xprev = x[b,:t+1] # (t,C)\n","        xbow[b,t] = torch.mean(xprev, 0)"],"metadata":{"id":"EwRfNHmbMfag","executionInfo":{"status":"ok","timestamp":1683798282945,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["* second method"],"metadata":{"id":"Dzh5gdAcMy6N"}},{"cell_type":"code","source":["# version 2: using matrix multiply for a weighted aggregation\n","wei = torch.tril(torch.ones(T, T))\n","wei = wei / wei.sum(1, keepdim=True)\n","xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n","torch.allclose(xbow, xbow2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFyTtJTqMszJ","executionInfo":{"status":"ok","timestamp":1683798317418,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"6c0125ba-4757-42f9-e3c7-d1ae5d09d5cb"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["* third method"],"metadata":{"id":"cQuGiGIvM3Gc"}},{"cell_type":"code","source":["tril = torch.tril(torch.ones(T, T))\n","wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","print(wei)\n","wei = F.softmax(wei, dim=-1)\n","print(wei)\n","xbow3 = wei @ x\n","torch.allclose(xbow, xbow3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e21-IGhrM1LN","executionInfo":{"status":"ok","timestamp":1683798353404,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"386c8153-d480-4f8f-fab1-24feea707298"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0.]])\n","tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["* Now the main method #self-attention!"],"metadata":{"id":"FZVdO9s6NA2R"}},{"cell_type":"code","source":["torch.manual_seed(42)\n","B,T,C = 4,8,32 # batch, time, channels\n","x = torch.randn(B,T,C)\n","\n","# let's see a single Head perform self-attention\n","head_size = 16\n","key = nn.Linear(C, head_size, bias=False)\n","query = nn.Linear(C, head_size, bias=False)\n","value = nn.Linear(C, head_size, bias=False)\n","k = key(x)   # (B, T, 16)\n","q = query(x) # (B, T, 16)\n","wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ==> (B, T, T)\n","\n","tril = torch.tril(torch.ones(T, T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","\n","v = value(x)\n","out = wei @ v\n","\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IerzIlDM4hb","executionInfo":{"status":"ok","timestamp":1683798501486,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"9d29ae7c-6f7e-4d1e-91e2-9eeb085a2226"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 16])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Here the sum of the weights equals 1 and its distrubution shows the importance of each token"],"metadata":{"id":"DKowzir_NpVe"}},{"cell_type":"code","source":["wei[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFBi5oK8NiNF","executionInfo":{"status":"ok","timestamp":1683798506728,"user_tz":-180,"elapsed":409,"user":{"displayName":"Mohamad Alamin Yassin","userId":"08486611753121899969"}},"outputId":"26d57a26-7385-4ed8-a8e3-68f5f396d39d"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.1905, 0.8095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3742, 0.0568, 0.5690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.1288, 0.3380, 0.1376, 0.3956, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.4311, 0.0841, 0.0582, 0.3049, 0.1217, 0.0000, 0.0000, 0.0000],\n","        [0.0537, 0.3205, 0.0694, 0.2404, 0.2568, 0.0592, 0.0000, 0.0000],\n","        [0.3396, 0.0149, 0.5165, 0.0180, 0.0658, 0.0080, 0.0373, 0.0000],\n","        [0.0165, 0.0375, 0.0144, 0.1120, 0.0332, 0.4069, 0.3136, 0.0660]],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Some useful notes:\n","- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n","- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens (unlike CNN).\n","- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n","- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n","- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n","- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"],"metadata":{"id":"Ba5Jkv6cOhkL"}},{"cell_type":"code","source":[],"metadata":{"id":"GH-OSyiRNl8L"},"execution_count":null,"outputs":[]}]}